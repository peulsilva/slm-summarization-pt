{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 24 20:58:30 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A5000               Off |   00000000:01:00.0 Off |                  Off |\n",
      "| 49%   71C    P2             95W /  230W |    1602MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A    135232      G   /usr/libexec/Xorg                              94MiB |\n",
      "|    0   N/A  N/A    135261      G   /usr/bin/gnome-shell                           16MiB |\n",
      "|    0   N/A  N/A    585506    C+G   ...man/.pyenv/versions/venv/bin/python       1473MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import evaluate\n",
    "from datasets import load_dataset, Dataset\n",
    "from huggingface_hub import notebook_login\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth.chat_templates import train_on_responses_only, get_chat_template\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm\n",
    "import torch\n",
    "import scienceplots\n",
    "plt.style.use(['science', 'no-latex'])\n",
    "from IPython.display import clear_output\n",
    "from src.pytorch_utils import count_parameters\n",
    "from src.text_utils import trim_text_to_token_limit\n",
    "from src.train_test_split import stratified_train_test_split\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3758275ba24a02b08995edb9425338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_per_process_memory_fraction(0.6, device=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Fine Tuning (SFT)\n",
    "\n",
    "In this notebook we will finetune our Small Language Model on the target completions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.2.15: Fast Qwen2 patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    GPU: NVIDIA RTX A5000. Max memory: 23.651 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 6000\n",
    "dtype = None \n",
    "load_in_4bit = True\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen2-0.5B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    cache_dir = '/Data'\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LoRA adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.2.15 patched 24 layers with 24 QKV layers, 24 O layers and 24 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, \n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 323,917,696 \n",
      "Trainable Parameters: 8,798,208 (3.0 %)\n"
     ]
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data = pd.read_json(\"data/wikipedia_dataset.json\")\n",
    "completions_df = pd.read_pickle(\"data/generated_dataset_100_Meta-Llama-3.1-8B-Instruct-bnb-4bit_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.merge(\n",
    "    base_data,\n",
    "    completions_df,\n",
    "    on = 'id'\n",
    ")[['id', 'text', 'num_tokens', 'generated_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>generated_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9513</td>\n",
       "      <td>Conhecimento (do latim cognoscere, \"ato de con...</td>\n",
       "      <td>1785</td>\n",
       "      <td>O conhecimento Ã© o ato ou efeito de conhecer, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1337</td>\n",
       "      <td>O nazismo (), oficialmente nacional-socialismo...</td>\n",
       "      <td>2864</td>\n",
       "      <td>O nazismo Ã© uma ideologia associada a Adolf Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1718</td>\n",
       "      <td>Sergipe Ã© uma das 27 unidades federativas do B...</td>\n",
       "      <td>3041</td>\n",
       "      <td>Sergipe Ã© um estado brasileiro localizado na R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3832</td>\n",
       "      <td>SuÃ­Ã§a ( ; em suÃ­Ã§o-alemÃ£o: Schwyz ou Schwiiz ;...</td>\n",
       "      <td>674</td>\n",
       "      <td>A SuÃ­Ã§a Ã© uma repÃºblica federal composta por 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>302</td>\n",
       "      <td>AristÃ³teles (; Estagira,  â€“ Atenas, ) foi um f...</td>\n",
       "      <td>2666</td>\n",
       "      <td>AristÃ³teles foi um filÃ³sofo e polÃ­mata da GrÃ©c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                               text  num_tokens  \\\n",
       "0  9513  Conhecimento (do latim cognoscere, \"ato de con...        1785   \n",
       "1  1337  O nazismo (), oficialmente nacional-socialismo...        2864   \n",
       "2  1718  Sergipe Ã© uma das 27 unidades federativas do B...        3041   \n",
       "3  3832  SuÃ­Ã§a ( ; em suÃ­Ã§o-alemÃ£o: Schwyz ou Schwiiz ;...         674   \n",
       "4   302  AristÃ³teles (; Estagira,  â€“ Atenas, ) foi um f...        2666   \n",
       "\n",
       "                                      generated_text  \n",
       "0  O conhecimento Ã© o ato ou efeito de conhecer, ...  \n",
       "1  O nazismo Ã© uma ideologia associada a Adolf Hi...  \n",
       "2  Sergipe Ã© um estado brasileiro localizado na R...  \n",
       "3  A SuÃ­Ã§a Ã© uma repÃºblica federal composta por 2...  \n",
       "4  AristÃ³teles foi um filÃ³sofo e polÃ­mata da GrÃ©c...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform a stratified train-test split, maintaining the distribution of number of tokens     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df , temp = stratified_train_test_split(text_df, test_size=0.4)\n",
    "test_df, val_df = stratified_train_test_split(temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Number of tokens')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.figure(figsize = (8,5))\n",
    "\n",
    "sns.histplot(train_df, x = 'num_tokens', stat = 'density', bins = 20, label = 'train')\n",
    "sns.histplot(test_df, x = 'num_tokens', stat='density', bins = 20, label = 'test')\n",
    "sns.histplot(val_df, x = 'num_tokens', stat='density', bins = 20, label = 'val')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"qwen-2.5\",\n",
    ")\n",
    "\n",
    "def format_row(row):\n",
    "    prompt = f'''\n",
    "        VocÃª Ã© um assistente virtual que deve gerar resumos de textos em portuguÃªs. \n",
    "        Seu resumo deve ter, no mÃ¡ximo {n_words} palavras e conter todas as informaÃ§Ãµes principais do texto.\n",
    "        Esse Ã© o texto:\n",
    "\n",
    "        {row['text']}\n",
    "        \n",
    "        FaÃ§a um resumo de no mÃ¡ximo {n_words} palavras do texto acima.\n",
    "    '''\n",
    "\n",
    "    row['conversations'] = [{'role': 'user', \"content\": prompt}, {'role': 'assistant', 'content': row['generated_text']}]\n",
    "    return row\n",
    "\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
    "    return { \"text\" : texts, }\n",
    "\n",
    "def generate_and_tokenize_prompt(text):\n",
    "    # Generate the full prompt with the assistant's response\n",
    "    tokenized_full_prompt = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "    # Clone the input_ids to create labels\n",
    "    labels = tokenized_full_prompt.input_ids.clone()\n",
    "\n",
    "    # Find the position of \"<assistant>\" in the prompt\n",
    "    prompt_text = text[:text.find(\">assistant\")] + \">assistant\"\n",
    "    end_prompt_idx = len(tokenizer(prompt_text, return_tensors=\"pt\")[\"input_ids\"][0])\n",
    "\n",
    "    # Mask all tokens before \"<assistant>\" with -100\n",
    "    labels[:, :end_prompt_idx] = -100\n",
    "\n",
    "    return {\n",
    "        'input_ids': tokenized_full_prompt.input_ids.flatten(),\n",
    "        'labels': labels.flatten(),\n",
    "        'attention_mask': tokenized_full_prompt.attention_mask.flatten(),\n",
    "    }\n",
    "\n",
    "def preprocess_df(df):\n",
    "    temp_df = df.progress_apply(format_row, axis =1)\n",
    "    temp_df = formatting_prompts_func(temp_df)\n",
    "\n",
    "    tokens = []\n",
    "    for t in tqdm(temp_df['text']):\n",
    "        tokens.append(generate_and_tokenize_prompt(t))\n",
    "\n",
    "    \n",
    "    tokens_dataset = Dataset.from_list(tokens)\n",
    "    return tokens_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:01<00:00, 2406.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3000/3000 [00:22<00:00, 132.30it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 3017.11it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:06<00:00, 144.72it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 2982.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:06<00:00, 145.38it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = preprocess_df(train_df)\n",
    "val_dataset = preprocess_df(val_df)\n",
    "test_dataset = preprocess_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'labels', 'attention_mask'],\n",
       "    num_rows: 3000\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset= val_dataset,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    # compute_metrics = compute_metrics,\n",
    "    args = SFTConfig(\n",
    "        # eval_strategy = 'steps',\n",
    "        # eval_steps = 1,\n",
    "        per_device_train_batch_size = 16,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        dataset_num_proc = 2,\n",
    "        packing = False, # Can make training 5x faster for short sequences.\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        learning_rate = 2e-5,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        hub_model_id= \"peulsilva/slm-pt\",\n",
    "        save_total_limit=1,\n",
    "        # output_dir = \"/Data\",\n",
    "        # report_to = \"none\", # Use this for WandB etc,\n",
    "        # push_to_hub=True,\n",
    "        # save_steps = 10,\n",
    "        # hub_strategy=\"every_save\",\n",
    "        max_seq_length = max_seq_length,\n",
    "        # dataset_text_field = 'text',\n",
    "        batch_eval_metrics = True,\n",
    "        # padding = True,\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 3,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 64 | Total steps = 47\n",
      " \"-____-\"     Number of trainable parameters = 8,798,208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 18:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.129700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.139900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.074800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.156500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.122500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.091500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.060200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.968800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.978700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.948900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.942800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.941300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.941800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.898100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.856900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.884500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.847500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.915500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.866200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.885500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.854400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.871600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.893900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.819900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.864100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.847900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.831900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.825600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.881700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.864300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.866500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.846300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.844700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.856300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.846400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.869200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.860600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.823000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.842700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: You're not saving a tokenizer as well?\n",
      "You can do it separately via `tokenizer.push_to_hub(...)`\n",
      "Unsloth: You are pushing to hub, but you passed your HF username = peulsilva.\n",
      "We shall truncate peulsilva/qwen-0.5b-instruct-summary-pt-checkpoint0 to qwen-0.5b-instruct-summary-pt-checkpoint0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 25.62 out of 62.29 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 137.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b7e7dce5924a9e9ac255bcad6b585c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/594 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5d08d9eaff4effbe19e7f7149747cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved merged model to https://huggingface.co/peulsilva/qwen-0.5b-instruct-summary-pt-checkpoint0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a45cf182ad4a41bdfc54b22daf20a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/600 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a7c97947d648019e4f782e54367c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 3,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 64 | Total steps = 47\n",
      " \"-____-\"     Number of trainable parameters = 8,798,208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 20:22, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.794200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.826400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.821100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.818500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.769100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.854500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.837300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.801800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.815100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.796400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.828600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.790600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.766900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.794300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.832900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.791000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.789100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.801800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.805700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.775800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.735900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.767900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.741400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.804200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.761200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.787700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.755100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.775600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.795900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.734100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.771300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.758200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.743600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.739600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.792100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.781900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.789200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.761500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.759200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.778600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.761500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.766900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.790200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.778700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.741900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.760300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: You are pushing to hub, but you passed your HF username = peulsilva.\n",
      "We shall truncate peulsilva/qwen-0.5b-instruct-summary-pt-checkpoint1 to qwen-0.5b-instruct-summary-pt-checkpoint1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 25.29 out of 62.29 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 127.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61240a860017425a8f4a8942f8a4925c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/594 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee211cdc9744fc183841f6e359a59bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved merged model to https://huggingface.co/peulsilva/qwen-0.5b-instruct-summary-pt-checkpoint1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100e29879c6c4af0aa3d5e8be758d91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/600 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9cad94531c461db58876668e8ba146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 3,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 64 | Total steps = 47\n",
      " \"-____-\"     Number of trainable parameters = 8,798,208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 18:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.714400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.747800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.743000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.732600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.695000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.769200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.729100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.737400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.732600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.715300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.752500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.713400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.693900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.721400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.759500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.717900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.714600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.723500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.728200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.700200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.662800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.694600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.670500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.731600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.720600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.710700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.726500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.672400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.705300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.693300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.682400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.677400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.728300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.719600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.730800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.698700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.698500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.719400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.704800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.708200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.730100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.717800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.681900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.700200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: You are pushing to hub, but you passed your HF username = peulsilva.\n",
      "We shall truncate peulsilva/qwen-0.5b-instruct-summary-pt-checkpoint2 to qwen-0.5b-instruct-summary-pt-checkpoint2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 25.07 out of 62.29 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 140.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d01943b9ea4245938839224971cb9fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/594 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97288a574a4492c8dd889cafa156704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved merged model to https://huggingface.co/peulsilva/qwen-0.5b-instruct-summary-pt-checkpoint2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba4e7c7f2854143b93df77fa1a9e58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/600 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8312601b1e9489dbd142bad355fc20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 3,000 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 16 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 64 | Total steps = 47\n",
      " \"-____-\"     Number of trainable parameters = 8,798,208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/47 06:33 < 14:31, 0.04 it/s, Epoch 0.32/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.654600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.688500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.682200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.671100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.641700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.720100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.677400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.684300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.691900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.672900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.708500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.673900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.655500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m----> 3\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      4\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpush_to_hub_merged(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeulsilva/qwen-0.5b-instruct-summary-pt-checkpoint\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeulsilva/qwen-0.5b-instruct-summary-pt-checkpoint\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   2242\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   2243\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   2244\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   2245\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   2246\u001b[0m     )\n",
      "File \u001b[0;32m<string>:329\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
      "File \u001b[0;32m<string>:73\u001b[0m, in \u001b[0;36m_unsloth_training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/accelerate/accelerator.py:2329\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2329\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    583\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "for epoch in range(n_epochs):\n",
    "    trainer.train()\n",
    "    trainer.model.push_to_hub_merged(f\"peulsilva/qwen-0.5b-instruct-summary-pt-checkpoint{epoch}\")\n",
    "    trainer.tokenizer.push_to_hub(f\"peulsilva/qwen-0.5b-instruct-summary-pt-checkpoint{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = torch.Tensor(train_dataset['labels'][0]) == -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([151644,   8948,    198,  ...,    198, 151644,  77091])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(train_dataset['input_ids'][0])[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen2ForCausalLM(\n",
       "      (model): Qwen2Model(\n",
       "        (embed_tokens): Embedding(151936, 896, padding_idx=151643)\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x Qwen2DecoderLayer(\n",
       "            (self_attn): Qwen2Attention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=896, out_features=896, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=896, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=896, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=896, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=128, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=896, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=128, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=896, out_features=896, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=896, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=896, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): Qwen2MLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=896, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4864, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=896, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=4864, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4864, out_features=896, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4864, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=896, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.tensor(train_dataset['input_ids'][0])[mask].unsqueeze(0).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644,   8948,    198,  ...,    198, 151644,  77091]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = trainer.model.generate(tokens, max_new_tokens = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   198,  41298,  24061,  80664,   3958,   4443,    518,    269,    308,\n",
       "          16568,  32217,  11632,   5652,  70483,   5249,   4154,  52097,    518,\n",
       "           4284,  15249,    902,  33192,    384,  89965,   3413,     13,    434,\n",
       "           6728,    518,    269,  12435,  12541,    976,  97796,    384,  89965,\n",
       "           3413,  38483,    220,     16,     24,     22,     16,     11,   9243,\n",
       "          32092,  21679,  16070,  41650,   5249,    976,  20009,  54639,   7953,\n",
       "            518,    269,    976,    220,     16,     24,     24,     24,     13,\n",
       "          25949,  17141,  81130,    976,  71285,     11,  24987,     11,    384,\n",
       "            511,   1352,    283,   4317,  15545,   9075,    409,  24987,     13,\n",
       "          25949,    518,   4284,   7953,    518,    269,    976, 135626,  97796,\n",
       "            384,  89965,  12652,     11,  18409,     84,  34999,  15433,    647,\n",
       "            287]], device='cuda:0')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated[:,tokens.shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHarry Dean Stanton Ã© um ator norte-americano conhecido por suas atuaÃ§Ãµes no cinema e televisÃ£o. Foi ator principalmente em filmes e televisÃ£o atÃ© 1971, mas jÃ¡ foi reconhecido em seu trabalho como ator em 1999. Ele nasceu em Irvine, Kentucky, e se formou na Universidade de Kentucky. Ele atua como ator em vÃ¡rios filmes e televisÃµes, incluindo Os Ving'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated[0][tokens.shape[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 28.57 out of 62.29 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 493.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67b3b10921642ddb038ca713b976a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/600 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8b3abbad334fd0b6dae83ea133283e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.70G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved merged model to https://huggingface.co/peulsilva/qwen-0.5b-instruct-summary-pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Qwen2TokenizerFast has no attribute push_to_hub_merged",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpush_to_hub_merged(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeulsilva/qwen-0.5b-instruct-summary-pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpush_to_hub_merged(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeulsilva/qwen-0.5b-instruct-summary-pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1108\u001b[0m, in \u001b[0;36mSpecialTokensMixin.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(attr_as_tokens) \u001b[38;5;28;01mif\u001b[39;00m attr_as_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m-> 1108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(key)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Qwen2TokenizerFast has no attribute push_to_hub_merged"
     ]
    }
   ],
   "source": [
    "trainer.model.push_to_hub_merged(\"peulsilva/qwen-0.5b-instruct-summary-pt\")\n",
    "trainer.tokenizer.push_to_hub(\"peulsilva/qwen-0.5b-instruct-summary-pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb693d7284c4412a2a9558cda5352cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.tokenizer.push_to_hub(\"peulsilva/qwen-0.5b-instruct-summary-pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeulsilva/qwen-0.5b-instruct-summary-pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/transformers/trainer.py:4792\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;66;03m# Wait for the current upload to be finished.\u001b[39;00m\n\u001b[1;32m   4791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish_current_push()\n\u001b[0;32m-> 4792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m upload_folder(\n\u001b[1;32m   4793\u001b[0m     repo_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhub_model_id,\n\u001b[1;32m   4794\u001b[0m     folder_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39moutput_dir,\n\u001b[1;32m   4795\u001b[0m     commit_message\u001b[38;5;241m=\u001b[39mcommit_message,\n\u001b[1;32m   4796\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   4797\u001b[0m     run_as_future\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m blocking,\n\u001b[1;32m   4798\u001b[0m     ignore_patterns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_*\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPREFIX_CHECKPOINT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-*\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   4799\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   4800\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_api.py:1524\u001b[0m, in \u001b[0;36mfuture_compatible.<locals>._inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_as_future(fn, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# Otherwise, call the function normally\u001b[39;00m\n\u001b[0;32m-> 1524\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_api.py:4658\u001b[0m, in \u001b[0;36mHfApi.upload_folder\u001b[0;34m(self, repo_id, folder_path, path_in_repo, commit_message, commit_description, token, repo_type, revision, create_pr, parent_commit, allow_patterns, ignore_patterns, delete_patterns, run_as_future)\u001b[0m\n\u001b[1;32m   4648\u001b[0m ignore_patterns \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m DEFAULT_IGNORE_PATTERNS\n\u001b[1;32m   4650\u001b[0m delete_operations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_folder_deletions(\n\u001b[1;32m   4651\u001b[0m     repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[1;32m   4652\u001b[0m     repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4656\u001b[0m     delete_patterns\u001b[38;5;241m=\u001b[39mdelete_patterns,\n\u001b[1;32m   4657\u001b[0m )\n\u001b[0;32m-> 4658\u001b[0m add_operations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_upload_folder_additions(\n\u001b[1;32m   4659\u001b[0m     folder_path,\n\u001b[1;32m   4660\u001b[0m     path_in_repo,\n\u001b[1;32m   4661\u001b[0m     allow_patterns\u001b[38;5;241m=\u001b[39mallow_patterns,\n\u001b[1;32m   4662\u001b[0m     ignore_patterns\u001b[38;5;241m=\u001b[39mignore_patterns,\n\u001b[1;32m   4663\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   4664\u001b[0m     repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m   4665\u001b[0m )\n\u001b[1;32m   4667\u001b[0m \u001b[38;5;66;03m# Optimize operations: if some files will be overwritten, we don't need to delete them first\u001b[39;00m\n\u001b[1;32m   4668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(add_operations) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_api.py:9174\u001b[0m, in \u001b[0;36mHfApi._prepare_upload_folder_additions\u001b[0;34m(self, folder_path, path_in_repo, allow_patterns, ignore_patterns, repo_type, token)\u001b[0m\n\u001b[1;32m   9166\u001b[0m     log(\n\u001b[1;32m   9167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt seems you are trying to upload a large folder at once. This might take some time and then fail if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   9168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe folder is too large. For such cases, it is recommended to upload in smaller batches or to use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   9169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   9170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   9171\u001b[0m     )\n\u001b[1;32m   9173\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart hashing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_repo_objects)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9174\u001b[0m operations \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   9175\u001b[0m     CommitOperationAdd(\n\u001b[1;32m   9176\u001b[0m         path_or_fileobj\u001b[38;5;241m=\u001b[39mrelpath_to_abspath[relpath],  \u001b[38;5;66;03m# absolute path on disk\u001b[39;00m\n\u001b[1;32m   9177\u001b[0m         path_in_repo\u001b[38;5;241m=\u001b[39mprefix \u001b[38;5;241m+\u001b[39m relpath,  \u001b[38;5;66;03m# \"absolute\" path in repo\u001b[39;00m\n\u001b[1;32m   9178\u001b[0m     )\n\u001b[1;32m   9179\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m relpath \u001b[38;5;129;01min\u001b[39;00m filtered_repo_objects\n\u001b[1;32m   9180\u001b[0m ]\n\u001b[1;32m   9181\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished hashing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_repo_objects)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m operations\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/hf_api.py:9175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   9166\u001b[0m     log(\n\u001b[1;32m   9167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt seems you are trying to upload a large folder at once. This might take some time and then fail if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   9168\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe folder is too large. For such cases, it is recommended to upload in smaller batches or to use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   9169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`HfApi().upload_large_folder(...)`/`huggingface-cli upload-large-folder` instead. For more details, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   9170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   9171\u001b[0m     )\n\u001b[1;32m   9173\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart hashing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_repo_objects)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9174\u001b[0m operations \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m-> 9175\u001b[0m     CommitOperationAdd(\n\u001b[1;32m   9176\u001b[0m         path_or_fileobj\u001b[38;5;241m=\u001b[39mrelpath_to_abspath[relpath],  \u001b[38;5;66;03m# absolute path on disk\u001b[39;00m\n\u001b[1;32m   9177\u001b[0m         path_in_repo\u001b[38;5;241m=\u001b[39mprefix \u001b[38;5;241m+\u001b[39m relpath,  \u001b[38;5;66;03m# \"absolute\" path in repo\u001b[39;00m\n\u001b[1;32m   9178\u001b[0m     )\n\u001b[1;32m   9179\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m relpath \u001b[38;5;129;01min\u001b[39;00m filtered_repo_objects\n\u001b[1;32m   9180\u001b[0m ]\n\u001b[1;32m   9181\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished hashing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_repo_objects)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m operations\n",
      "File \u001b[0;32m<string>:5\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, path_in_repo, path_or_fileobj)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/_commit_api.py:195\u001b[0m, in \u001b[0;36mCommitOperationAdd.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Compute \"upload_info\" attribute\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_or_fileobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupload_info \u001b[38;5;241m=\u001b[39m UploadInfo\u001b[38;5;241m.\u001b[39mfrom_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_or_fileobj)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_or_fileobj, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupload_info \u001b[38;5;241m=\u001b[39m UploadInfo\u001b[38;5;241m.\u001b[39mfrom_bytes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_or_fileobj)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/lfs.py:84\u001b[0m, in \u001b[0;36mUploadInfo.from_path\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     83\u001b[0m     sample \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mpeek(\u001b[38;5;241m512\u001b[39m)[:\u001b[38;5;241m512\u001b[39m]\n\u001b[0;32m---> 84\u001b[0m     sha \u001b[38;5;241m=\u001b[39m sha_fileobj(file)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(size\u001b[38;5;241m=\u001b[39msize, sha256\u001b[38;5;241m=\u001b[39msha, sample\u001b[38;5;241m=\u001b[39msample)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/huggingface_hub/utils/sha.py:26\u001b[0m, in \u001b[0;36msha_fileobj\u001b[0;34m(fileobj, chunk_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mread(chunk_size)\n\u001b[0;32m---> 26\u001b[0m     sha\u001b[38;5;241m.\u001b[39mupdate(chunk)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.push_to_hub(\"peulsilva/qwen-0.5b-instruct-summary-pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
